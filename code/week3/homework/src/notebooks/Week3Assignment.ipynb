{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a850059d-5e11-4c8f-8be7-48bfc218f72a",
   "metadata": {},
   "source": [
    "# Week 3 Assignment\n",
    "> Due Sept 29\n",
    "\n",
    "## Task\n",
    "\n",
    "Using Linear-regression.train.csv provided, write a gradient descent algorithm to find the curve/line (having parameters θ1 and θ0 )that best fits the point based on the idea of linear regression.\n",
    "\n",
    "### Algorithm (Setup)\n",
    "\n",
    "1. Initialize both the parameters as 1.\n",
    "2. Set step size/learning rate to 0.01.\n",
    "3. You can stop if you have exhausted 100 iterations.\n",
    "4. You can also stop before if the change in the objective from a previous iteration is less than a tolerance (set to .001)\n",
    "\n",
    "### Deliverables (submit to week3assignment as a doc/docx file)\n",
    "\n",
    "1. Output the least squares error and parameters of the function learnt.\n",
    "2. Plot the least squares error in each iteration.\n",
    "3. In a separate figure, Plot the line found via the optimization (in red) and the original points (in blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb4e02e-e6a7-44e5-9668-f0f4d51fa779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eacd382-96b0-4ddf-af43-134ba719a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset\n",
    "linear_reg_train_csv_file = \"../data-raw/linear-regression.train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c0fc83-ce07-4d29-a846-437645749836",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(linear_reg_train_csv_file, \"r\") as input_csv:\n",
    "    df = pd.read_csv(input_csv,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4ae0be-66d1-4c0a-9f8d-2f3851b4a062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.773926</td>\n",
       "      <td>-1.124183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.846599</td>\n",
       "      <td>-1.211766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.324710</td>\n",
       "      <td>-0.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.306738</td>\n",
       "      <td>-2.085373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.980138</td>\n",
       "      <td>-1.356403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.773926 -1.124183\n",
       "1  5.846599 -1.211766\n",
       "2  4.324710 -0.362800\n",
       "3  2.306738 -2.085373\n",
       "4  4.980138 -1.356403"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d494593-ff27-4189-9fc9-55e39f246e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[0].to_numpy() # features\n",
    "y_train = df[1].to_numpy() # target values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1ba86-29b2-43bf-abc8-8ceb5d341764",
   "metadata": {},
   "source": [
    "## Compute the Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa8b931-6ad7-4e32-973d-222ab2469ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the cost\n",
    "def compute_cost(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    \n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b2d033-9a73-4014-bb47-b54863ddb8e4",
   "metadata": {},
   "source": [
    "## Gradient Descent Summary\n",
    "\n",
    "We have a linear model that predicts $f_{w,b}(x^{i})$:\n",
    "$$\n",
    "f_{w,b}(x^{i}) = wx^{i}+b \\tag{1}\n",
    "$$\n",
    "\n",
    "In linear regression, you utilize input training data to fit the parameters $w,b$ by minimizing a measure of the error between our predictions $f_{w,b}(x^{i})$ and the actual data $y^{i}$. The measure is called $cost, J(w,b)$. In training, you measure the cost over all of our training samples $(x^{i}, y^{i})$\n",
    "\n",
    "$$\n",
    "J(w,b) = \\frac{1}{2m}\\sum\\limits_{i=0}^{m-1}(f_{w,b}(x^{i})-y^{i})^{2} \\tag{2}\n",
    "$$\n",
    "\n",
    "In lecture, *gradient descent* was described as:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, parameters $w,b$ are updated simultaneously.\n",
    "\n",
    "The gradient is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m}\\sum\\limits_{i=0}^{m-1}(f_{w,b}(x^{i})-y^{i})x^{i} \\tag{4} \\newline\n",
    "\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m}\\sum\\limits_{i=0}^{m-1}(f_{w,b}(x^{i})-y^{i})x^{i} \\tag{5}\n",
    "\\end{align*}$$\n",
    "\n",
    "Here, *simultaneously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5ce36-1492-40ef-9ca6-b466363c38bc",
   "metadata": {},
   "source": [
    "### Implement Gradient Descent\n",
    "\n",
    "We will implement the gradient descent algorithm for one feature. We will need three functions:\n",
    "\n",
    "- `compute_gradient` implementing equations (4) and (5).\n",
    "- `compute_cost` implementing equation (2), which is already implemented.\n",
    "- `gradient_descent`, utilizing `compute_gradient` and `compute_cost`.\n",
    "\n",
    "Conventions:\n",
    "\n",
    "- The naming of python variables containing partial derivatives follow this pattern, $\\frac{\\partial J(w,b)}{\\partial b}$ will be `dj_db`.\n",
    "- w.r.t. is With Respect To, as in partial derivative of $J(w,b)$ With Respect To $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b7609-f079-4f42-acd9-117e52082fb2",
   "metadata": {},
   "source": [
    "### `compute_gradient`\n",
    "\n",
    "`compute_gradient` implements (4) and (5) above and returns $\\frac{\\partial J(w,b)}{\\partial w}$, $\\frac{\\partial J(w,b)}{\\partial b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27552b09-99e2-44eb-b25a-82dff96330f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
