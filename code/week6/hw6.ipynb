{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7552144-01c4-4946-96a8-298b9c8c4137",
   "metadata": {},
   "source": [
    "# Hw 3: Nearest Neighbors\n",
    "## Submit to Dropbox Hw3 by Oct 21 \n",
    "\n",
    "### Part 1. \n",
    "\n",
    "Your programs should read files provided. In this format, each instance is described on a single line. The feature values are separated by\n",
    "commas, and the last value on each line is the class label (for classification).  Lines starting with '%' are comments\n",
    "\n",
    "- Your programs should  implement a k-nearest neighbor learner in a function according to the following guidelines:\n",
    "  - Assume that for classification tasks, the class attribute is named 'class' and it is the last attribute listed among all the attributes.\n",
    "  - Assume that all features will be numeric.\n",
    "  - Use Euclidean distance to compute distances between instances.\n",
    "  - Implement basic k-NN.\n",
    "  - If there is a tie among multiple instances to be in the k-nearest neighbors, the tie should be broken in favor of those instances that come first in the data file.\n",
    "  - If there is a tie in the class predicted by the k-nearest neighbors, then among the classes that have the same number of votes, the tie should be broken in favor of the class comes first in the data file.\n",
    "- You should include a function myKNN and should accept three arguments as follows:\n",
    "  - myKNN(traindata,testdata, k)\n",
    "  - The myKNN function should use the training set and the given value of k to make classifications/predictions for every instance in the test set. This can be called from a main calling function.\n",
    "  - The main program should  use  p-fold cross validation (set p =10) with just the training data to select the value of k (used by NN) to use for the test set by evaluating k1 k2 k3…. (set it to any values you like) and selecting the one that results in the minimal cross-validated error within the training set.\n",
    "  - To measure error, you should use mean absolute error. The following link shows how to use cross validation with python, including generating indices for each fold.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "\n",
    "- As output, your programs should print the value of k used for the test set on the first line, and then the predictions for the test-set instances.\n",
    "- For each instance in the test set, your program should print one line of output with spaces separating the fields.\n",
    "- For a classification task, each output line should list the predicted class label, and actual class label.\n",
    "- This should be followed by a line listing the number of correctly classified test instances, and the total number of instances in the test set.\n",
    "- This should be followed by a line listing the mean absolute error for the test instances, and the total number of instances in the test set.\n",
    "- Copy and paste this output to the .docx file you will submit to canvas.\n",
    "\n",
    "You should test your code on the following two data sets:\n",
    "- yeast_train.txt\n",
    "- yeast_test.txt\n",
    "\n",
    "### Part 2.\n",
    "\n",
    "For this part you will explore the effect of the k parameter on predictive accuracy.\n",
    "\n",
    "- For the yeast data set, draw a plot showing how test-set accuracy varies as a function of k. Your plot should show accuracy for k = 1, 5, 10, 15, 20 after p-fold cross validation (where p=10).\n",
    "- For the yeast data set, construct confusion matrices for the k = 1 and k = 15 test-set results (you don’t need to do cross validation for this). Show these confusion matrices and briefly discuss what the matrices tell you about the effect of k on the misclassifications. See how to create confusion matrices here.\n",
    "\n",
    "http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "The python code for confusion matrices can be found at \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "Put these results in the .docx file (from both parts) and submit to dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77115a3f-a60c-461b-845d-2a1580406fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy.stats as sp\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b44541b-25bb-45ca-9574-5e39ba147641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    n, m= data.shape\n",
    "    avg = np.mean(data, axis=0)\n",
    "    for i in range(0, m):\n",
    "        temp = data[:,i] - avg[i]\n",
    "        s = np.std(data[:,i])\n",
    "        data[:,i] = temp / s\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac04d6a9-77ee-4409-9dc8-645d31379436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myKNN(train, label_train, test, k):\n",
    "    n1, m1 = train.shape\n",
    "    n2, m2 = test.shape\n",
    "    distance = euclidean_distances(train, test) # n1 by n2\n",
    "    distance = distance.transpose()\n",
    "    y_test = np.zeros(n2, dtype=str)\n",
    "    \n",
    "    for i in range (0, n2):\n",
    "        ind = np.argsort(distance[i,:])\n",
    "        k_top_labels = label_train[ind[0:k]]\n",
    "        # l = sp.mode(k_top_labels)\n",
    "        l = np.unique(k_top_labels)\n",
    "        y_test[i] = st.mode(l)\n",
    "\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "340b9322-b1cd-446a-a58f-3345c067104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1039, 8)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/yeast_train.txt\", header=None)\n",
    "label_train = train.iloc[:, 8]\n",
    "train = train.iloc[:,0:8]\n",
    "n1, m1 = train.shape\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de489f4a-3daf-4fac-bcc1-93c91c0681b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 8)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"./data/yeast_test.txt\", header=None)\n",
    "label_test = test.iloc[:, 8]\n",
    "test = test.iloc[:,0:8]\n",
    "n2, m2 = test.shape\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "837dc063-e1f1-4161-bd33-71b6b3b46307",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((train, test), axis = 0)\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0270b75b-76db-467f-9304-ca0caf55d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[0:n1, :]\n",
    "test = data[n1:n1+n2, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a588aa0-6fd3-40b4-8261-0ad9fa120958",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([94], dtype='int64')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# kf.get_n_splits(train)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(train):\n\u001b[0;32m---> 14\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m \u001b[43mmyKNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# return values is prediction\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     n \u001b[38;5;241m=\u001b[39m test_index\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     16\u001b[0m     acc \u001b[38;5;241m=\u001b[39m ((y_test \u001b[38;5;241m==\u001b[39m label_train[test_index])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m n[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m, in \u001b[0;36mmyKNN\u001b[0;34m(train, label_train, test, k)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m0\u001b[39m, n2):\n\u001b[1;32m      9\u001b[0m     ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distance[i,:])\n\u001b[0;32m---> 10\u001b[0m     k_top_labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# l = sp.mode(k_top_labels)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     l \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(k_top_labels)\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/series.py:1072\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[0;32m-> 1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/series.py:1099\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1102\u001b[0m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1109\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/School/Fall2023/CS732_Machine_Learning/code/week6/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6175\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6174\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([94], dtype='int64')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"k\", \"accuracy\"])\n",
    "\n",
    "k_results = []\n",
    "accuracy_results = [] \n",
    "# Homework\n",
    "# k_choices = np.arange(10, 100, step=10)\n",
    "k_choices = np.array([1, 5, 10, 15, 20])\n",
    "\n",
    "for k in k_choices:\n",
    "    kf = KFold(n_splits=10)\n",
    "    # kf.get_n_splits(train)\n",
    "\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        y_test = myKNN(train=train[train_index], label_train=label_train[train_index], test=train[test_index,:], k=k) # return values is prediction\n",
    "        n = test_index.shape\n",
    "        acc = ((y_test == label_train[test_index]).astype('uint8')).sum() / n[0]\n",
    "        k_results.append(k)\n",
    "        accuracy_results.append(acc)\n",
    "\n",
    "df[\"k\"] = k_results\n",
    "df[\"accuracy\"] = accuracy_results\n",
    "df = df.groupby(\"k\").mean().reset_index()\n",
    "mae = df.sort_values(by=\"accuracy\", ascending=False).iloc[0][\"accuracy\"]\n",
    "best_k = df.sort_values(by=\"accuracy\", ascending=False).iloc[0][\"k\"]\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd221b-b946-4aa6-8b4e-7e3871f47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.lineplot(x = k_results, y = accuracy_results, markers=\"o\")\n",
    "plt.xlabel(\"K values\")\n",
    "plt.ylabel(\"Accuracy Scores\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
